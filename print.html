<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>vidformer - Video Data Transformation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">vidformer - Video Data Transformation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/ixlab/vidformer" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="vidformer"><a class="header" href="#vidformer">vidformer</a></h1>
<p><a href="https://github.com/ixlab/vidformer/actions/workflows/test.yml"><img src="https://github.com/ixlab/vidformer/actions/workflows/test.yml/badge.svg" alt="Test" /></a>
<a href="https://pypi.org/project/vidformer/"><img src="https://img.shields.io/pypi/v/vidformer.svg" alt="PyPI version" /></a>
<a href="https://crates.io/crates/vidformer"><img src="https://img.shields.io/crates/v/vidformer" alt="Crates.io Version" /></a>
<a href="https://colab.research.google.com/github/ixlab/vidformer/blob/main/misc/Colab_Vidformer.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a>
<a href="https://github.com/ixlab/vidformer/blob/main/LICENSE"><img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" alt="License" /></a></p>
<p>A research project providing infrastructure for video-native interfaces and accelerating computer vision visualization.
Developed by the OSU Interactive Data Systems Lab.</p>
<h2 id="-why-vidformer"><a class="header" href="#-why-vidformer">🎯 Why vidformer</a></h2>
<p>Vidformer efficiently transforms videos, enabling faster annotation, editing, and processing of video data—without having to focus on performance.</p>
<p>It uses a declarative specification format to represent transformations. This enables:</p>
<ul>
<li>
<p><strong>Transparent Optimization:</strong> Vidformer optimizes the execution of declarative specifications just like a relational database optimizes relational queries.</p>
</li>
<li>
<p><strong>Lazy/Deferred Execution:</strong> Video results can be retrieved on-demand, allowing for practically instantaneous playback of video results.</p>
</li>
</ul>
<p>Vidformer usually renders videos 2-3x faster than cv2, and hundreds of times faster when serving videos on-demand.</p>
<p>Vidformer builds on open technologies you may already use:</p>
<ul>
<li><strong>OpenCV:</strong> A <code>cv2</code>-compatible interface ensures both you (and LLMs) can use  existing knowlege and code.</li>
<li><strong>Supervision:</strong> <a href="https://supervision.roboflow.com/latest/">Supervision</a>-compatible annotators make visualizing computer vision models trivial.</li>
<li><strong>FFmpeg:</strong> Built on the same libraries, codecs, and formats that run the world.</li>
<li><strong>Jupyter:</strong> View transformed videos instantly right in your notebook.</li>
<li><strong>HTTP Live Streaming (HLS):</strong> Serve transformed videos over a network directly into any media player.</li>
<li><strong>Apache OpenDAL:</strong> Access source videos no matter where they are stored.</li>
</ul>
<h2 id="-quick-start"><a class="header" href="#-quick-start">🚀 Quick Start</a></h2>
<p><a href="https://colab.research.google.com/github/ixlab/vidformer/blob/main/misc/Colab_Vidformer.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></p>
<p>The easiest way to get started is using vidformer's <code>cv2</code> frontend, which allows most Python OpenCV visualization scripts to replace <code>import cv2</code> with <code>import vidformer.cv2 as cv2</code>:</p>
<pre><code class="language-bash">git clone https://github.com/ixlab/vidformer
cd vidformer
docker build -t igni -f Dockerfile .
docker-compose -f vidformer-igni/docker-compose-local.yaml up
</code></pre>
<pre><code class="language-python">import vidformer.cv2 as cv2

cap = cv2.VideoCapture("my_input.mp4")
fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

out = cv2.VideoWriter("my_output.mp4", cv2.VideoWriter_fourcc(*"mp4v"),
                        fps, (width, height))
while True:
    ret, frame = cap.read()
    if not ret:
      break

    cv2.putText(frame, "Hello, World!", (100, 100), cv2.FONT_HERSHEY_SIMPLEX,
                1, (255, 0, 0), 1)
    out.write(frame)

cap.release()
out.release()
</code></pre>
<p>You can find details on this in our <a href="https://ixlab.github.io/vidformer/getting-started.html">Getting Started Guide</a>.</p>
<h2 id="-documentation"><a class="header" href="#-documentation">📘 Documentation</a></h2>
<ul>
<li><a href="https://ixlab.github.io/vidformer/">🌐 Website</a></li>
<li><a href="https://ixlab.github.io/vidformer/getting-started.html">🚀 Getting Started</a></li>
<li><a href="https://ixlab.github.io/vidformer/vidformer-py.html">🐍 vidformer-py</a></li>
<li><a href="https://ixlab.github.io/vidformer/vidformer/">🛠️ vidformer core</a></li>
</ul>
<h2 id="about-the-project"><a class="header" href="#about-the-project">About the project</a></h2>
<p><strong>File Layout</strong>:</p>
<ul>
<li><a href="./vidformer/"><em>./vidformer</em></a>: The core transformation library</li>
<li><a href="./vidformer-py/"><em>./vidformer-py</em></a>: A Python video editing client</li>
<li><a href="./vidformer-cli/"><em>./vidformer-cli</em></a>: A command-line interface</li>
<li><a href="./vidformer-igni/"><em>./vidformer-igni</em></a>: The second generation vidformer server</li>
<li><a href="./snake-pit/"><em>./snake-pit</em></a>: The main vidformer test suite</li>
<li><a href="./docs/"><em>./docs</em></a>: The <a href="https://ixlab.github.io/vidformer/">vidformer website</a></li>
</ul>
<p>Vidformer components are detailed <a href="https://ixlab.github.io/vidformer/modules.html">here</a>.</p>
<p>❌ vidformer is <em><strong>NOT</strong></em>:</p>
<ul>
<li>A conventional video editor (like Premiere Pro or Final Cut)</li>
<li>A video database/VDBMS</li>
<li>A natural language query interface for video</li>
<li>A computer vision library (like OpenCV)</li>
<li>A computer vision AI model (like CLIP or Yolo)</li>
</ul>
<p>However, vidformer is strongly complementary to each of these.
If you're working on any of the later four, vidformer may be for you.</p>
<p><strong>License:</strong> Vidformer is open source under <a href="./LICENSE">Apache-2.0</a>.
Contributions are welcome.</p>
<p><strong>Acknowledgements:</strong> Vidformer is supported by the U.S. National Science Foundation under Awards #2118240 and #1910356.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h1>
<p>Vidformer can be run in a cloud deployment or locally.</p>
<h2 id="in-the-cloud-start-here"><a class="header" href="#in-the-cloud-start-here">In the cloud (start here):</a></h2>
<p>Walk through a demo using a hosted guest account: <a href="https://colab.research.google.com/github/ixlab/vidformer/blob/main/misc/Colab_Vidformer.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></p>
<h2 id="local"><a class="header" href="#local">Local:</a></h2>
<p>You can host a server yourself (<a href="./install.html">here</a>).
Installing locally allows for accessing the local file system and saving video results.</p>
<ul>
<li><a href="./getting-started-cv2.html">Getting started with the <code>cv2</code> compatability layer</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="local-install"><a class="header" href="#local-install">Local Install</a></h1>
<p>You can deploy the server locally with docker:</p>
<pre><code class="language-bash">git clone https://github.com/ixlab/vidformer
cd vidformer
docker build -t igni -f Dockerfile .
docker-compose -f vidformer-igni/docker-compose-local.yaml up
</code></pre>
<p>Vidformer-py can be installed with pip:</p>
<pre><code class="language-bash">pip3 install vidformer
</code></pre>
<p>There are two ways to connect the client to the server.
Either use the environment variables printed out by the server or set it manually:</p>
<pre><code class="language-python">import vidformer as vf
import vidformer.cv2 as cv2

cv2.set_server(vf.Server("&lt;ENDPOINT&gt;", "&lt;API_KEY&gt;"))
</code></pre>
<h2 id="run-admin-commands"><a class="header" href="#run-admin-commands">Run admin commands</a></h2>
<p>Admin commands can be run from inside the server container:</p>
<pre><code class="language-bash">docker-compose -f vidformer-igni/docker-compose-local.yaml exec igni bash
vidformer-igni user ls
</code></pre>
<p>Run <code>vidformer-igni --help</code> for other commands.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started---cv2"><a class="header" href="#getting-started---cv2">Getting Started - cv2</a></h1>
<p>This is a walkthrough of getting started with vidformer OpenCV <code>cv2</code> compatability layer.</p>
<blockquote>
<p>⚠️ Adding <code>cv2</code> functions is a work in progress. See the <a href="./opencv-filters.html">cv2 filters page</a> for which functions have been implemented.</p>
</blockquote>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<p>See <a href="./install.html">Installation guide</a></p>
<p>Or you can <a href="https://colab.research.google.com/github/ixlab/vidformer/blob/main/misc/Colab_Vidformer.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a>.</p>
<h2 id="hello-world"><a class="header" href="#hello-world">Hello, world!</a></h2>
<p>Copy in your video, or use ours:</p>
<pre><code class="language-bash">curl -O https://f.dominik.win/data/dve2/tos_720p.mp4
</code></pre>
<p>Then just replace <code>import cv2</code> with <code>import vidformer.cv2 as cv2</code>.
Here's our example script:</p>
<pre><code class="language-python">import vidformer.cv2 as cv2

cap = cv2.VideoCapture("tos_720p.mp4")
fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

out = cv2.VideoWriter("output.mp4", cv2.VideoWriter_fourcc(*"mp4v"),
                        fps, (width, height))
while True:
    ret, frame = cap.read()
    if not ret:
      break

    cv2.putText(frame, "Hello, World!", (100, 100), cv2.FONT_HERSHEY_SIMPLEX,
                1, (255, 0, 0), 1)
    out.write(frame)

cap.release()
out.release()
</code></pre>
<h3 id="stream-the-results"><a class="header" href="#stream-the-results">Stream the Results</a></h3>
<p>Saving videos to disk works, but we can also display them in the notebook.
Since we stream the results and only render them on demand this can start practically instantly!</p>
<p>First, replace <code>"output.mp4"</code> with <code>None</code> to skip writing the video to disk.
Then you can use <code>cv2.vidplay()</code> to play the video!</p>
<pre><code class="language-python">import vidformer.cv2 as cv2

cap = cv2.VideoCapture("tos_720p.mp4")
fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

out = cv2.VideoWriter(None, cv2.VideoWriter_fourcc(*"mp4v"),
                        fps, (width, height))
while True:
    ret, frame = cap.read()
    if not ret:
      break

    cv2.putText(frame, "Hello, World!", (100, 100), cv2.FONT_HERSHEY_SIMPLEX,
                1, (255, 0, 0), 1)
    out.write(frame)

cap.release()
out.release()

cv2.vidplay(out)
</code></pre>
<blockquote>
<p>⚠️ By default <code>cv2.vidplay()</code> will return a video which plays in a Jupyter Notebook. If running outside a jupyter notebook you can pass <code>method="link"</code> to return a link instead.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-vidformer-modules"><a class="header" href="#the-vidformer-modules">The vidformer modules</a></h1>
<p>vidformer is a highly modular suite of tools that work together:</p>
<ul>
<li>
<p><a href="./vidformer-py.html"><em>vidformer-py</em></a>: A Python 🐍 client for declarative video synthesis</p>
<ul>
<li>Provides an easy-to-use library for symbolically representing transformed videos</li>
<li>Acts as a client for a vidformer server</li>
<li><strong>Using vidformer-py is the best place to get started</strong></li>
</ul>
</li>
<li>
<p><a href="./libvidformer.html"><em>libvidformer</em></a>: The core data-oriented declarative video editing library</p>
<ul>
<li>An embedded video processing execution engine with low-level interfaces</li>
<li>Systems code, written in Rust 🦀</li>
<li><strong>You should use if:</strong> You are building a VDBMS or other multimodal data-system <em>infrastructure</em>.</li>
<li><strong>You should <em>not</em> use if:</strong> You just want to use vidformer in your workflows or projects.</li>
</ul>
</li>
<li>
<p><a href="./vidformer-igni.html"><em>vidformer-igni</em></a>: The vidformer server</p>
<ul>
<li>A multi-tenant scale-out server</li>
<li>Designed for Video on Demand <em>only</em>
<ul>
<li>Does not support full-video exports</li>
<li>All video sources must be over the network, not local</li>
</ul>
</li>
<li>Enables live streaming and waiting on external dependencies for even lower time-to-playback latency</li>
</ul>
</li>
</ul>
<p><strong>Client libraries in other languages:</strong>
Writing a vidformer client library for other languages is simple.
It's a few hundred lines of code, and you just have to construct some JSON.
Contributions or suggestions for other languages are welcome.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vidformer---video-data-transformation-library"><a class="header" href="#vidformer---video-data-transformation-library">vidformer - Video Data Transformation Library</a></h1>
<p><a href="https://crates.io/crates/vidformer"><img src="https://img.shields.io/crates/v/vidformer" alt="Crates.io Version" /></a>
<a href="https://github.com/ixlab/vidformer/blob/main/LICENSE"><img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" alt="License" /></a></p>
<p>(lib)vidformer is a core video synthesis/transformation library.
It handles the movement, control flow, and processing of video and conventional (non-video) data.</p>
<p><strong>Quick links:</strong></p>
<ul>
<li><a href="https://crates.io/crates/vidformer">📦 Crates.io</a></li>
<li><a href="https://ixlab.github.io/vidformer/vidformer/">📘 Documentation</a></li>
<li><a href="https://github.com/ixlab/vidformer/tree/main/vidformer/">🧑‍💻 Source Code</a></li>
</ul>
<h2 id="about"><a class="header" href="#about">About</a></h2>
<ul>
<li>It's written in Rust 🦀
<ul>
<li>So it does some fancy parallel processing and does so safely</li>
</ul>
</li>
<li>Uses the <a href="https://www.ffmpeg.org/documentation.html">FFmpeg libav libraries</a> for multimedia stuff
<ul>
<li>So it should work with nearly every video file ever made</li>
</ul>
</li>
<li>Uses <a href="https://opendal.apache.org/">Apache OpenDAL</a> for I/O
<ul>
<li>So it can access videos in a bunch of storage services</li>
</ul>
</li>
<li>Implements filters using <a href="https://opencv.org/">OpenCV</a></li>
</ul>
<h2 id="building"><a class="header" href="#building">Building</a></h2>
<p>This crate requires linking with FFmpeg, as detailed in the <code>rusty_ffmpeg</code> crate.
We currently target FFmpeg 7.0.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vidformer-py"><a class="header" href="#vidformer-py">vidformer-py</a></h1>
<p><a href="https://pypi.org/project/vidformer/"><img src="https://img.shields.io/pypi/v/vidformer.svg" alt="PyPI version" /></a>
<a href="https://github.com/ixlab/vidformer/blob/main/LICENSE"><img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" alt="License" /></a></p>
<p>vidformer-py is a Python 🐍 frontend for <a href="https://github.com/ixlab/vidformer">vidformer</a>.
It has an API compatability layer with OpenCV cv2, as well as some <a href="https://github.com/roboflow/supervision">supervision</a> annotators.
Our <a href="https://ixlab.github.io/vidformer/getting-started.html">getting started guide</a> explains how to use it.</p>
<p><strong>Quick links:</strong></p>
<ul>
<li><a href="https://pypi.org/project/vidformer/">📦 PyPI</a></li>
<li><a href="https://ixlab.github.io/vidformer/vidformer-py/pdoc/">📘 Documentation - vidformer-py</a></li>
<li><a href="https://ixlab.github.io/vidformer/vidformer-py/pdoc/vidformer/cv2.html">📘 Documentation - vidformer.cv2</a></li>
<li><a href="https://ixlab.github.io/vidformer/vidformer-py/pdoc/vidformer/supervision.html">📘 Documentation - vidformer.supervision</a></li>
<li><a href="https://github.com/ixlab/vidformer/tree/main/vidformer-py/">🧑‍💻 Source Code</a></li>
</ul>
<p><strong>Publish:</strong></p>
<pre><code class="language-bash"> export FLIT_USERNAME='__token__' FLIT_PASSWORD='&lt;token&gt;'
flit publish
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vidformer-igni"><a class="header" href="#vidformer-igni">vidformer-igni</a></h1>
<p>The vidformer server for the cloud.</p>
<p><strong>Quick links:</strong></p>
<ul>
<li><a href="https://github.com/ixlab/vidformer/tree/main/vidformer-igni/">🧑‍💻 Source Code</a></li>
</ul>
<h2 id="local-setup"><a class="header" href="#local-setup">Local Setup</a></h2>
<pre><code class="language-bash">git clone https://github.com/ixlab/vidformer
cd vidformer
docker build -t igni -f Dockerfile .
docker-compose -f vidformer-igni/docker-compose-local.yaml up
</code></pre>
<h2 id="development-setup"><a class="header" href="#development-setup">Development Setup</a></h2>
<pre><code class="language-bash">docker-compose -f docker-compose-db.yaml up
export 'IGNI_DB=postgres://igni:igni@localhost:5432/igni'
cargo run -- user add --name test --api-key test --permissions test
cargo run --release -- server --config igni.toml
</code></pre>
<h2 id="server-deployment"><a class="header" href="#server-deployment">Server Deployment</a></h2>
<pre><code class="language-bash"># From vidformer project root
docker build -t igni -f Dockerfile .
docker-compose -f vidformer-igni/docker-compose-prod.yaml up
</code></pre>
<p>For tls certs:</p>
<pre><code class="language-bash">docker-compose -f vidformer-igni/docker-compose-prod.yaml run --rm certbot certonly --webroot --webroot-path /var/www/certbot/ -d api.example.com -d cdn.example.com
</code></pre>
<h2 id="guest-account-setup-for-colab-notebook"><a class="header" href="#guest-account-setup-for-colab-notebook">Guest account setup (for colab notebook)</a></h2>
<pre><code class="language-bash">docker ps
docker exec -it &lt;igni container&gt; bash
vidformer-igni user add --name guest --permissions guest --api-key VF_GUEST
vidformer-igni user ls
vidformer-igni source add --user-id 98f6aa2a-e622-40bc-a0cd-e05f73f7e398 --name vf-sample-media/tos_720p.mp4 --stream-idx 0 --storage-service http --storage-config '{"endpoint":"https://f.dominik.win"}'
vidformer-igni source add --user-id 98f6aa2a-e622-40bc-a0cd-e05f73f7e398 --name vf-sample-media/tos_720p-yolov8x-seg-masks.mkv --stream-idx 0 --storage-service http --storage-config '{"endpoint":"https://f.dominik.win"}'

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="filters"><a class="header" href="#filters">Filters</a></h1>
<ul>
<li><a href="./builtin-filters.html">For the vidformer builtin filters</a></li>
<li><a href="./opencv-filters.html">For the OpenCV/cv2 filters</a></li>
<li><a href="./udf-filters.html">For using User Defined Filters (UDFs)</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="built-in-filters"><a class="header" href="#built-in-filters">Built-in Filters</a></h1>
<p>While most applications will use user-defined filters, vidformer ships with a handful of built-in filters to get you started:</p>
<h2 id="drawtext"><a class="header" href="#drawtext">DrawText</a></h2>
<p><code>DrawText</code> does exactly what it sounds like: draw text on a frame.</p>
<p>For example:</p>
<pre><code class="language-python">DrawText(frame, text="Hello, world!", x=100, y=100, size=48, color="white")
</code></pre>
<h2 id="boundingbox"><a class="header" href="#boundingbox">BoundingBox</a></h2>
<p><code>BoundingBox</code> draws bounding boxes on a frame.</p>
<p>For example:</p>
<pre><code class="language-python">BoundingBox(frame, bounds=obj)
</code></pre>
<p>Where <code>obj</code> is JSON with this schema:</p>
<pre><code class="language-json">[
  {
    "class": "person",
    "confidence": 0.916827917098999,
    "x1": 683.0721842447916,
    "y1": 100.92174338626751,
    "x2": 1006.863525390625,
    "y2": 720
  },
  {
    "class": "dog",
    "confidence": 0.902531921863556,
    "x1": 360.8750813802083,
    "y1": 47.983140622720974,
    "x2": 606.76171875,
    "y2": 717.9591837897462
  }
]
</code></pre>
<h2 id="scale"><a class="header" href="#scale">Scale</a></h2>
<p>The <code>Scale</code> filter transforms one frame type to another.
It changes both resolution and pixel format.
This is <em>the most important filter</em> and is <em>essential</em> for building with vidformer.</p>
<p>Arguments:</p>
<pre><code class="language-python">Scale(
    frame: Frame,
    width: int = None,
    height: int = None,
    pix_fmt: str = None)
</code></pre>
<p>By default missing <code>width</code>, <code>height</code> and <code>format</code> values are set to match <code>frame</code>.
<code>pix_fmt</code> must match ffmpeg's name for a pixel format.</p>
<p>For example:</p>
<pre><code class="language-python">frame = Scale(frame, width=1280, height=720, pix_fmt="rgb24")
</code></pre>
<h2 id="ipc"><a class="header" href="#ipc">IPC</a></h2>
<p>IPC allows for calling User-Defined Filters (UDFs) running on the same system.
It is an <strong>infrastructure-level filter</strong> and is used to implement other filters.
It is configured with a <code>socket</code> and <code>func</code>, the filter's name, both strings.</p>
<p>The <code>IPC</code> filter can not be directly invoked, rather IPC filters are constructed by a server upon request.
This can be difficult, but <a href="./vidformer-py.html">vidformer-py</a> handles this for you.
As of right now <code>IPC</code> only supports <code>rgb24</code> frames.</p>
<h2 id="hstack--vstack"><a class="header" href="#hstack--vstack">HStack &amp; VStack</a></h2>
<p>HStack &amp; VStack allow for composing multiple frames together, stacking them either horizontally or vertically.
It tries to automatically find a reasonable layout.</p>
<p>Arguments:</p>
<pre><code class="language-python">HStack(
    *frames: list[Frame],
    width: int,
    height: int,
    format: str)
</code></pre>
<p>At least one frame is required, along with a <code>width</code>, <code>height</code> and <code>format</code>.</p>
<p>For example:</p>
<pre><code class="language-python">compilation = HStack(left_frame, right_frame, width=1280, height=720, format="rgb24")
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="opencvcv2-functions"><a class="header" href="#opencvcv2-functions">OpenCV/cv2 Functions</a></h1>
<p>See <a href="https://ixlab.github.io/vidformer/vidformer-py-cv2/">vidformer.cv2 API docs</a>.</p>
<blockquote>
<p>⚠️ The <code>cv2</code> module is a work in progress. If you find a bug or need a missing feature implemented feel free to <a href="https://github.com/ixlab/vidformer/issues">file an issue</a> or contribute yourself!</p>
</blockquote>
<p>Legend:</p>
<ul>
<li>✅ - Support</li>
<li>🔸 - Support via OpenCV cv2</li>
<li>❌ - Not yet implemented</li>
</ul>
<h2 id="vidformer-specific-functions"><a class="header" href="#vidformer-specific-functions">Vidformer-specific Functions</a></h2>
<ul>
<li><code>cv2.vidplay(video2)</code> - Play a VideoWriter, Spec, or Source</li>
<li><code>VideoWriter.spec()</code> - Return the Spec of an output video</li>
<li><code>Frame.numpy()</code> - Return the frame as a numpy array</li>
<li><code>cv2.setTo</code> - The OpenCV <code>Mat.setTo</code> function (not in cv2)</li>
<li><code>cv2.zeros</code> - Create a black frame (equiv to <code>numpy.zeros</code>)</li>
</ul>
<h2 id="opencv"><a class="header" href="#opencv">opencv</a></h2>
<div class="table-wrapper"><table><thead><tr><th><strong>Class</strong></th><th><strong>Status</strong></th></tr></thead><tbody>
<tr><td>VideoCapture</td><td>✅</td></tr>
<tr><td>VideoWriter</td><td>✅</td></tr>
<tr><td>VideoWriter_fourcc</td><td>✅</td></tr>
</tbody></table>
</div><div class="table-wrapper"><table><thead><tr><th><strong>Function</strong></th><th><strong>Status</strong></th></tr></thead><tbody>
<tr><td>imread</td><td>✅</td></tr>
<tr><td>imwrite</td><td>✅</td></tr>
</tbody></table>
</div>
<h2 id="opencvimgproc"><a class="header" href="#opencvimgproc">opencv.imgproc</a></h2>
<p>Drawing Functions:</p>
<div class="table-wrapper"><table><thead><tr><th><strong>Function</strong></th><th><strong>Status</strong></th></tr></thead><tbody>
<tr><td>arrowedLine</td><td>✅</td></tr>
<tr><td>circle</td><td>✅</td></tr>
<tr><td>clipLine</td><td>❌</td></tr>
<tr><td>drawContours</td><td>❌</td></tr>
<tr><td>drawMarker</td><td>❌</td></tr>
<tr><td>ellipse</td><td>✅</td></tr>
<tr><td>ellipse2Poly</td><td>❌</td></tr>
<tr><td>fillConvexPoly</td><td>❌</td></tr>
<tr><td>fillPoly</td><td>❌</td></tr>
<tr><td>getFontScaleFromHeight</td><td>🔸</td></tr>
<tr><td>getTextSize</td><td>🔸</td></tr>
<tr><td>line</td><td>✅</td></tr>
<tr><td>polylines</td><td>❌</td></tr>
<tr><td>putText</td><td>✅</td></tr>
<tr><td>rectangle</td><td>✅</td></tr>
</tbody></table>
</div>
<h2 id="opencvcore"><a class="header" href="#opencvcore">opencv.core</a></h2>
<div class="table-wrapper"><table><thead><tr><th><strong>Function</strong></th><th><strong>Status</strong></th></tr></thead><tbody>
<tr><td>addWeighted</td><td>✅</td></tr>
<tr><td>resize</td><td>✅</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="hardware-acceleration"><a class="header" href="#hardware-acceleration">Hardware Acceleration</a></h1>
<p>This page details how to compile vidformer with NVIDIA NVENC and similar hardware accelerated codecs.
We assume Docker is running on a system with CUDA.
Other codecs also work, see <a href="https://trac.ffmpeg.org/wiki/HWAccelIntro">FFmpeg docs</a>.
Testing this with GitHub Actions is impossible, so it may be a tad outdated.</p>
<p>The container must be run with these arguments: <code>--gpus all --runtime=nvidia -e NVIDIA_DRIVER_CAPABILITIES=all</code>.
If using Dev Containers, these can be added to the <code>devcontainer.json</code> file under <code>runArgs</code>.</p>
<p>The <code>scripts/deps_ffmpeg.sh</code> needs to be patched to include <code>--enable-ffnvcodec</code>.</p>
<p>Then you can run this in the container:</p>
<pre><code class="language-bash"># From project root delete old FFmpeg build
rm -rf ffmpeg

sudo apt update -y
sudo apt install build-essential yasm cmake libtool libc6 libc6-dev unzip wget libnuma1 libnuma-dev -y

# Install (see https://trac.ffmpeg.org/wiki/HWAccelIntro)
rm -rf nv-codec-headers
git clone https://git.videolan.org/git/ffmpeg/nv-codec-headers.git
cd nv-codec-headers
# NOTE: Depending on your driver, you may want to checkout an older version tag here
make
sudo make install
cd -

# Install cuda
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
  &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo sed -i -e '/experimental/ s/^#//g' /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo apt update -y
sudo apt-get install -y nvidia-container-toolkit nvidia-cuda-toolkit

# Build ffmpeg
./scripts/deps_ffmpeg.sh

# Test it out
./ffmpeg/build/bin/ffmpeg -i myinputvid.mp4 -c:v h264_nvenc out.mp4 -y
</code></pre>
<p>Now you can recompile vidformer and use hardware accelerated codecs.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="roadmap"><a class="header" href="#roadmap">Roadmap</a></h1>
<p>An unordered list of potential future features:</p>
<ul>
<li>
<p>Full GPU Acceleration</p>
</li>
<li>
<p>WebAssembly user defined filters</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="faq"><a class="header" href="#faq">FAQ</a></h1>
<h3 id="what-video-formats-does-vidformer-support"><a class="header" href="#what-video-formats-does-vidformer-support">What video formats does vidformer support?</a></h3>
<p>In short, essentially everything.
vidformer uses the <a href="https://ffmpeg.org/">FFmpeg/libav*</a> libraries internally, so any media FFmpeg works with should work in vidformer as well.
We support many container formats (e.g., mp4, mov) and codecs (e.g., H.264, VP8).</p>
<p>A full list of supported codecs enabled in a vidformer build can be found by running:</p>
<pre><code class="language-bash">vidformer-cli codecs
</code></pre>
<h3 id="can-i-access-remote-videos-on-the-internet"><a class="header" href="#can-i-access-remote-videos-on-the-internet">Can I access remote videos on the internet?</a></h3>
<p>Yes, vidformer uses <a href="https://opendal.apache.org/">Apache OpenDAL</a> for I/O, so most common data/storage access protocols are supported.
However, not all storage services are enabled in distributed binaries.
We guarantee that HTTP, S3, and the local filesystem are always available.</p>
<h3 id="how-does-vidformer-compare-to-ffmpeg"><a class="header" href="#how-does-vidformer-compare-to-ffmpeg">How does vidformer compare to FFmpeg?</a></h3>
<p>vidformer is far more expressive than the FFmpeg filter interface.
Mainly, vidformer is designed for work around data, so edits are created programatically and edits can reference data.
Also, vidformer enables serving resut videos on demand.</p>
<p>vidformer uses the <a href="https://ffmpeg.org/">FFmpeg/libav*</a> libraries internally, so any media FFmpeg works with should also work in vidformer.</p>
<h3 id="how-does-vidformer-compare-to-opencvcv2"><a class="header" href="#how-does-vidformer-compare-to-opencvcv2">How does vidformer compare to OpenCV/cv2?</a></h3>
<p>vidformer orchestrates data movment in video synthesis tasks, but does not implement image processing directly.
Most use cases will still use OpenCV for this.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
